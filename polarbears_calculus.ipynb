{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == INSTALACIONES REQUERIDAS ==\n",
    "!pip install geopy tqdm skyfield xarray netCDF4 rioxarray requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == IMPORTS ==\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from geopy.distance import geodesic\n",
    "from tqdm import tqdm\n",
    "from functools import lru_cache\n",
    "import requests\n",
    "import xarray as xr\n",
    "from skyfield.api import load, Topos\n",
    "from skyfield.almanac import sunrise_sunset, find_discrete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == CARGAR EFEMÉRIDES ==\n",
    "eph = load('de421.bsp')\n",
    "ts = load.timescale()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == CARGAR DATASET SEA ICE ==\n",
    "# Cambia la URL por tu dataset real, o sube el archivo .nc a Colab\n",
    "!wget -O sea_ice_concentration.nc \"URL_DEL_NETCDF_DE_SEA_ICE\"\n",
    "ds_seaice = xr.open_dataset('sea_ice_concentration.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == FUNCIONES BASE ==\n",
    "\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "def calculate_velocity(distance, time_diff):\n",
    "    return distance / time_diff if time_diff > 0 else 0\n",
    "\n",
    "def calculate_acceleration(velocity1, velocity2, time_diff):\n",
    "    return (velocity2 - velocity1) / time_diff if time_diff > 0 else 0\n",
    "\n",
    "@lru_cache(maxsize=100000)\n",
    "def cached_daylight_info(date_str, lat, lon):\n",
    "    date = datetime.strptime(date_str, '%Y-%m-%d').replace(tzinfo=timezone.utc)\n",
    "    t0 = ts.utc(date.year, date.month, date.day)\n",
    "    t1 = ts.utc((date + timedelta(days=1)).year, (date + timedelta(days=1)).month, (date + timedelta(days=1)).day)\n",
    "    observer = Topos(latitude_degrees=lat, longitude_degrees=lon)\n",
    "    f = sunrise_sunset(eph, observer)\n",
    "    times, events = find_discrete(t0, t1, f)\n",
    "    sunrise = sunset = None\n",
    "    for ti, event in zip(times, events):\n",
    "        if event == 1: sunrise = ti.utc_datetime()\n",
    "        elif event == 0: sunset = ti.utc_datetime()\n",
    "    if sunrise and sunset:\n",
    "        daylight_hours = (sunset - sunrise).total_seconds() / 3600\n",
    "        return daylight_hours, False, False\n",
    "    elif sunrise is None and sunset is None:\n",
    "        alt = eph['Earth'] + observer\n",
    "        sun_alt = alt.at(t0).observe(eph['Sun']).apparent().altaz()[0].degrees\n",
    "        if sun_alt > 0: return 24.0, False, True\n",
    "        else: return 0.0, True, False\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "@lru_cache(maxsize=100000)\n",
    "def get_env_data(lat, lon, date_str):\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        'latitude': lat,\n",
    "        'longitude': lon,\n",
    "        'start_date': date_str,\n",
    "        'end_date': date_str,\n",
    "        'daily': ['temperature_2m_max', 'cloudcover', 'windspeed_10m_max'],\n",
    "        'timezone': 'UTC'\n",
    "    }\n",
    "    try:\n",
    "        r = requests.get(url, params=params, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        temp = data['daily']['temperature_2m_max'][0]\n",
    "        cloud = data['daily']['cloudcover'][0]\n",
    "        wind = data['daily']['windspeed_10m_max'][0]\n",
    "        return temp, cloud, wind\n",
    "    except:\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "def get_sea_ice_cover(lat, lon, date_str):\n",
    "    try:\n",
    "        date = np.datetime64(date_str)\n",
    "        val = ds_seaice['sea_ice_concentration'].sel(time=date, method='nearest') \\\n",
    "            .sel(lat=lat, lon=lon, method='nearest').values.item()\n",
    "        return val\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "cached_sea_ice = lru_cache(maxsize=100000)(get_sea_ice_cover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == EJEMPLO CARGA DATASET ==\n",
    "# df = pd.read_csv('polarBear_CTCRWlocations_chukchiBeaufort_1985-2017.csv')\n",
    "# Asegúrate que timestamp es datetime UTC\n",
    "# df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)\n",
    "\n",
    "# == PREPARAR DATAFRAME ==\n",
    "df = df.sort_values(['UniqueAnimalID', 'timestamp']).reset_index(drop=True)\n",
    "\n",
    "df['prev_lat'] = df.groupby('UniqueAnimalID')['mu_lat'].shift(1)\n",
    "df['prev_lon'] = df.groupby('UniqueAnimalID')['mu_lon'].shift(1)\n",
    "df['prev_time'] = df.groupby('UniqueAnimalID')['timestamp'].shift(1)\n",
    "df['prev_se_x'] = df.groupby('UniqueAnimalID')['se_mu_x'].shift(1)\n",
    "df['prev_se_y'] = df.groupby('UniqueAnimalID')['se_mu_y'].shift(1)\n",
    "\n",
    "df['time_diff_hours'] = (df['timestamp'] - df['prev_time']).dt.total_seconds() / 3600\n",
    "\n",
    "# Error estándar total en metros y desplazamiento\n",
    "df['se_total'] = np.sqrt(df['se_mu_x']**2 + df['se_mu_y']**2)\n",
    "df['prev_se_total'] = np.sqrt(df['prev_se_x']**2 + df['prev_se_y']**2)\n",
    "\n",
    "# Calcular distancia y error en km\n",
    "df['distance_km'] = df.apply(\n",
    "    lambda r: geodesic((r['prev_lat'], r['prev_lon']), (r['mu_lat'], r['mu_lon'])).kilometers\n",
    "    if pd.notnull(r['prev_lat']) else 0, axis=1)\n",
    "\n",
    "df['distance_error_km'] = (df['se_total'].fillna(0) + df['prev_se_total'].fillna(0)) / 1000\n",
    "\n",
    "# Ajustar distancia restando error (no negativo)\n",
    "df['distance_adj_km'] = (df['distance_km'] - df['distance_error_km']).clip(lower=0)\n",
    "\n",
    "# Calcular velocidad con distancia ajustada\n",
    "df['velocity_kmh'] = df['distance_adj_km'] / df['time_diff_hours']\n",
    "df.loc[df['time_diff_hours'] == 0, 'velocity_kmh'] = 0\n",
    "\n",
    "# Calcular aceleración (velocidad actual - anterior) / tiempo\n",
    "df['prev_velocity_kmh'] = df.groupby('UniqueAnimalID')['velocity_kmh'].shift(1)\n",
    "df['acceleration_kmh2'] = (df['velocity_kmh'] - df['prev_velocity_kmh']) / df['time_diff_hours']\n",
    "df.loc[df['time_diff_hours'] == 0, 'acceleration_kmh2'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == CALCULAR DAYLIGHT INFO CON tqdm Y lru_cache ==\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "df['date_str'] = df['timestamp'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df[['daylight_hours', 'is_polar_night', 'is_midnight_sun']] = \\\n",
    "    pd.DataFrame(df.progress_apply(lambda r: cached_daylight_info(r['date_str'], r['mu_lat'], r['mu_lon']), axis=1).tolist(), index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == CONSULTAR DATOS AMBIENTALES Y MARCAR EN EL DATAFRAME ==\n",
    "def fetch_env(row):\n",
    "    temp, cloud, wind = get_env_data(row['mu_lat'], row['mu_lon'], row['date_str'])\n",
    "    sea_ice = cached_sea_ice(row['mu_lat'], row['mu_lon'], row['date_str'])\n",
    "    return pd.Series({'temp_surface': temp, 'cloud_cover': cloud, 'wind_speed': wind, 'sea_ice_cover': sea_ice})\n",
    "\n",
    "df_env = df.progress_apply(fetch_env, axis=1)\n",
    "df = pd.concat([df, df_env], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
