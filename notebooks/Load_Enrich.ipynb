{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d89bd8",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80399092",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec43613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xarray netCDF4 geopy tqdm skyfield requests pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8248b7",
   "metadata": {},
   "source": [
    "### Import librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b04c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from functools import lru_cache\n",
    "from numpy import radians, sin, cos, arctan2, degrees\n",
    "from pyproj import Transformer\n",
    "from skyfield.api import load, Topos\n",
    "from skyfield.almanac import find_discrete, sunrise_sunset\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bd44e1",
   "metadata": {},
   "source": [
    "### Funciones de c√°lculo\n",
    "* **Posici√≥n, distancia y tiempo solar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033814a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_position_mc(lat, lon, se_x, se_y, n_samples=50):\n",
    "    lats = np.random.normal(lat, se_y, n_samples)\n",
    "    lons = np.random.normal(lon, se_x, n_samples)\n",
    "    return lats.mean(), lons.mean()\n",
    "\n",
    "# def adjusted_position_mc(lat, lon, se_x, se_y, n_samples=50):\n",
    "#     # Convertir error est√°ndar (en metros) a grados\n",
    "#     lat_std_deg = se_y / 111000  # 111 km ‚âà 111000 m\n",
    "#     lon_std_deg = se_x / (111000 * np.cos(np.radians(lat)) + 1e-6)  # evitar divisi√≥n por cero\n",
    "#     lats = np.random.normal(lat, lat_std_deg, n_samples)\n",
    "#     lons = np.random.normal(lon, lon_std_deg, n_samples)\n",
    "#     return lats.mean(), lons.mean()\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1; dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
    "    return 2*R*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "def calculate_velocity(distance_km, time_sec):\n",
    "    return (distance_km / time_sec) * 3600 if time_sec>0 else 0\n",
    "\n",
    "def calculate_acceleration(v1, v2, time_sec):\n",
    "    return (v2 - v1) / (time_sec/3600) if time_sec>0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e3017a",
   "metadata": {},
   "source": [
    "#### **Horas de luz - efem√©rides**\n",
    "\n",
    " Tablas o datos que indican las posiciones de los cuerpos celestes (como el Sol, la Luna, los planetas, etc.) en el cielo, para fechas y horas espec√≠ficas.\n",
    "\n",
    "En astronom√≠a, se usan para saber cu√°ndo ocurren eventos importantes, como:\n",
    "\n",
    "    - Salida y puesta del Sol üåÑüåá\n",
    "\n",
    "    - Salida y puesta de la Luna üåïüåò\n",
    "\n",
    "    - Duraci√≥n del d√≠a (horas de luz)\n",
    "\n",
    "    - Fases lunares, eclipses, etc.\n",
    "\n",
    "Por ejemplo, puedes usar _Skyfield_ para:\n",
    "\n",
    "    - Saber cu√°ndo sale el Sol en una latitud y longitud determinada.\n",
    "\n",
    "    - Calcular las horas de luz en el √Årtico, donde hay fen√≥menos extremos como el Sol de medianoche o la noche polar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef5cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eph = load('de421.bsp')\n",
    "ts = load.timescale()\n",
    "@lru_cache(maxsize=50000)\n",
    "def get_daylight(lat, lon, date_str):\n",
    "    d = datetime.strptime(date_str,'%Y-%m-%d').replace(tzinfo=timezone.utc)\n",
    "    t0 = ts.utc(d.year, d.month, d.day)\n",
    "    t1 = ts.utc((d+timedelta(days=1)).year, (d+timedelta(days=1)).month, (d+timedelta(days=1)).day)\n",
    "    obs = Topos(latitude_degrees=lat, longitude_degrees=lon)\n",
    "    f = sunrise_sunset(eph, obs)\n",
    "    times, events = find_discrete(t0, t1, f)\n",
    "    sunr = suns = None\n",
    "    for ti, ev in zip(times, events):\n",
    "        if ev==1: sunr = ti.utc_datetime()\n",
    "        elif ev==0: suns = ti.utc_datetime()\n",
    "    if sunr and suns:\n",
    "        dh = (suns - sunr).total_seconds()/3600\n",
    "        return dh, False, False\n",
    "    else:\n",
    "        alt = eph['Earth']+obs\n",
    "        sun_alt = alt.at(t0).observe(eph['Sun']).apparent().altaz()[0].degrees\n",
    "        if sun_alt>0: return 24.0, False, True\n",
    "        else: return 0.0, True, False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49aa97c",
   "metadata": {},
   "source": [
    "#### **Datos ambientales remotos**\n",
    "\n",
    "* **Cobertura de hielo**\n",
    "\n",
    "\n",
    "datos ambientales satelitales en forma de grilla a trav√©s del URL que corresponde a un servidor ERDDAP del gobierno de EE.UU., espec√≠ficamente del NOAA PolarWatch. Proporciona acceso a \n",
    "\n",
    "En concreto, este endpoint:\n",
    "\n",
    "https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nh1day\n",
    "\n",
    "se refiere al producto de concentraci√≥n diaria de hielo marino del hemisferio norte, conocido como:\n",
    "\n",
    "NSIDC-0051 / G02202 Version 4 ‚Äî Northern Hemisphere Daily Sea Ice Concentration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00008178",
   "metadata": {},
   "source": [
    "    Filtrar por intervalo 2007 -2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6333915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    cdr_seaice_conc                 (time, ygrid, xgrid) float32 9GB ...\n",
      "    melt_onset_day_cdr_seaice_conc  (time, ygrid, xgrid) float32 9GB ...\n",
      "    nsidc_bt_seaice_conc            (time, ygrid, xgrid) float32 9GB ...\n",
      "    nsidc_nt_seaice_conc            (time, ygrid, xgrid) float32 9GB ...\n",
      "    qa_of_cdr_seaice_conc           (time, ygrid, xgrid) float32 9GB ...\n",
      "    spatial_interpolation_flag      (time, ygrid, xgrid) float32 9GB ...\n",
      "    stdev_of_cdr_seaice_conc        (time, ygrid, xgrid) float32 9GB ...\n",
      "    temporal_interpolation_flag     (time, ygrid, xgrid) float32 9GB ...\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "url = 'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nh1day'\n",
    "ds = xr.open_dataset(url, engine='netcdf4')\n",
    "\n",
    "print(ds.data_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb80596",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nh1day'\n",
    "ds = xr.open_dataset(url, engine='netcdf4').sel(time=slice('1985-01-01','2017-12-31'))\n",
    "# ds = ds.sel(time=slice('2007-01-01', '2017-12-31'))\n",
    "ds = ds.sel(time=slice('2009-01-01', '2009-12-31'))\n",
    "vars_env = ['cdr_seaice_conc','temp_surface','wind_speed','cloud_cover']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c8ce07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rerddapxtracto import rxtracto\n",
    "import pandas as pd\n",
    "import rerddap\n",
    "\n",
    "# Dataset y variables\n",
    "dataset_id = 'nsidcG02202v4nh1day'\n",
    "vars_env = ['cdr_seaice_conc']  # Solo esta existe en este dataset\n",
    "\n",
    "# Preparar info del dataset\n",
    "info = rerddap.Rerddap(dataset_id, protocol='griddap')\n",
    "info.get_info()\n",
    "\n",
    "# Preparar coordenadas y fechas\n",
    "xpos = df_final['adj_lon'].tolist()\n",
    "ypos = df_final['adj_lat'].tolist()\n",
    "tpos = df_final['date_str'].tolist()\n",
    "\n",
    "# DataFrame para concatenar resultados\n",
    "env_dataframes = []\n",
    "\n",
    "# Extracci√≥n por variable existente\n",
    "for var in vars_env:\n",
    "    resp = rxtracto(\n",
    "        info,\n",
    "        parameter=var,\n",
    "        xcoord=xpos,\n",
    "        ycoord=ypos,\n",
    "        tcoord=tpos,\n",
    "        xName='xgrid',\n",
    "        yName='ygrid',\n",
    "        tName='time'\n",
    "    )\n",
    "    \n",
    "    df_var = pd.DataFrame({\n",
    "        f'{var}_mean': resp[f'mean {var}'],\n",
    "        f'{var}_stdev': resp[f'stdev {var}']\n",
    "    })\n",
    "\n",
    "    env_dataframes.append(df_var)\n",
    "\n",
    "# Concatenar todas las columnas extra√≠das\n",
    "df_env = pd.concat(env_dataframes, axis=1)\n",
    "\n",
    "# Combinar con df_final\n",
    "df_final = pd.concat([df_final.reset_index(drop=True), df_env.reset_index(drop=True)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b72c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@lru_cache(maxsize=50000)\n",
    "def get_env(ds, var, lat, lon, date_str):\n",
    "    try:\n",
    "        return float(ds[var].sel(time=np.datetime64(date_str), latitude=lat, longitude=lon, method='nearest').values)\n",
    "    except: return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88783799",
   "metadata": {},
   "source": [
    "La proyecci√≥n polar es una forma de representar zonas cercanas a los polos (como el √Årtico) en un mapa plano. En lugar de usar latitud y longitud directamente (como en los mapas comunes), transforma esas coordenadas en un sistema centrado en el polo.\n",
    "\n",
    "üßä ¬øPor qu√© se usa?\n",
    "\n",
    "   Porque en regiones polares, las l√≠neas de longitud se juntan mucho y los mapas se deforman. La proyecci√≥n polar mantiene mejor las distancias y formas en esas zonas.\n",
    "\n",
    "üìå En los datos satelitales como los del hielo marino:  \n",
    "\n",
    "No est√°n en lat/lon directamente, sino en una grilla con una proyecci√≥n polar.  \n",
    "\n",
    "Para extraer un valor (como concentraci√≥n de hielo) en una lat/lon, necesitas convertir esa lat/lon a coordenadas de esa grilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9009e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definici√≥n del transformador: de lat/lon (WGS84) a proyecci√≥n polar (usamos EPSG:3413 como est√°ndar NOAA √Årtico)\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", \"EPSG:3413\", always_xy=True)\n",
    "\n",
    "# Funci√≥n de conversi√≥n\n",
    "def convert_to_projected(lat, lon):\n",
    "    x, y = transformer.transform(lon, lat)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b181e66",
   "metadata": {},
   "source": [
    "### **Datos CSV principal**  \n",
    "\n",
    "    Cargar y ordenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22200c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueAnimalID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mu_lat</th>\n",
       "      <th>mu_lon</th>\n",
       "      <th>se_mu_x</th>\n",
       "      <th>se_mu_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7/1/1986 0:00</td>\n",
       "      <td>69.7687</td>\n",
       "      <td>-141.3759</td>\n",
       "      <td>14589</td>\n",
       "      <td>14589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7/1/1986 6:00</td>\n",
       "      <td>69.7703</td>\n",
       "      <td>-141.3863</td>\n",
       "      <td>12248</td>\n",
       "      <td>12248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7/1/1986 12:00</td>\n",
       "      <td>69.7718</td>\n",
       "      <td>-141.3942</td>\n",
       "      <td>9375</td>\n",
       "      <td>9375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7/1/1986 18:00</td>\n",
       "      <td>69.7730</td>\n",
       "      <td>-141.3960</td>\n",
       "      <td>5835</td>\n",
       "      <td>5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7/2/1986 0:00</td>\n",
       "      <td>69.7738</td>\n",
       "      <td>-141.3834</td>\n",
       "      <td>2517</td>\n",
       "      <td>2517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueAnimalID       timestamp   mu_lat    mu_lon  se_mu_x  se_mu_y\n",
       "0               1   7/1/1986 0:00  69.7687 -141.3759    14589    14589\n",
       "1               1   7/1/1986 6:00  69.7703 -141.3863    12248    12248\n",
       "2               1  7/1/1986 12:00  69.7718 -141.3942     9375     9375\n",
       "3               1  7/1/1986 18:00  69.7730 -141.3960     5835     5835\n",
       "4               1   7/2/1986 0:00  69.7738 -141.3834     2517     2517"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/polarBear_CTCRWlocations_chukchiBeaufort_1985-2017.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f98b5a",
   "metadata": {},
   "source": [
    "    Filtrar 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df[(df['timestamp'].dt.year == 2009)]\n",
    "df = df.sort_values(['UniqueAnimalID','timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1f49b",
   "metadata": {},
   "source": [
    "```varios calculos```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb2d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "res = []\n",
    "\n",
    "@lru_cache(maxsize=50000)\n",
    "def get_env(var, x_proj, y_proj, date_str):\n",
    "    try:\n",
    "        return float(ds[var].sel(\n",
    "            time=np.datetime64(date_str),\n",
    "            xgrid=x_proj,\n",
    "            ygrid=y_proj,\n",
    "            method='nearest'\n",
    "        ).values)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b914bc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(range(0, len(df), batch_size), desc='Batches'):\n",
    "    b = df.iloc[i:i+batch_size].copy()\n",
    "\n",
    "    # Ajuste de posici√≥n con Monte Carlo y rounding\n",
    "    b['adj_lat'], b['adj_lon'] = zip(*b.progress_apply(\n",
    "        lambda r: adjusted_position_mc(r['mu_lat'], r['mu_lon'], r['se_mu_x'], r['se_mu_y']), axis=1))\n",
    "    b['date_str'] = b['timestamp'].dt.strftime('%Y-%m-%d')\n",
    "    b['lat2'] = b['adj_lat'].round(2)\n",
    "    b['lon2'] = b['adj_lon'].round(2)\n",
    "    b['proj_x'], b['proj_y'] = zip(*b.progress_apply(lambda r: convert_to_projected(r['lat2'], r['lon2']), axis=1))\n",
    "\n",
    "\n",
    "    # Inicializamos columnas vac√≠as para luego asignar\n",
    "    b['distance_km'] = 0.0\n",
    "    b['velocity_kmh'] = 0.0\n",
    "    b['acceleration_kmh2'] = 0.0\n",
    "\n",
    "    # Procesar por UniqueAnimalID dentro del batch\n",
    "    for aid, g in b.groupby('UniqueAnimalID'):\n",
    "        g = g.reset_index()\n",
    "\n",
    "        if len(g) < 2:\n",
    "            continue  # saltar grupos con un solo punto\n",
    "\n",
    "        dists = [0.0]\n",
    "        vels = [0.0]\n",
    "        accs = [0.0]\n",
    "\n",
    "        for j in range(1, len(g)):\n",
    "            dt = (g.loc[j, 'timestamp'] - g.loc[j - 1, 'timestamp']).total_seconds()\n",
    "            dk = haversine_distance(g.loc[j - 1, 'adj_lat'], g.loc[j - 1, 'adj_lon'], g.loc[j, 'adj_lat'], g.loc[j, 'adj_lon'])\n",
    "            dists.append(dk)\n",
    "            vels.append(calculate_velocity(dk, dt))\n",
    "\n",
    "        for j in range(1, len(vels)):\n",
    "            dt_acc = (g.loc[j, 'timestamp'] - g.loc[j - 1, 'timestamp']).total_seconds()\n",
    "            accs.append(calculate_acceleration(vels[j - 1], vels[j], dt_acc))\n",
    "\n",
    "        # Ajustar tama√±o de accs si es mayor\n",
    "        if len(accs) > len(g):\n",
    "            accs = accs[:len(g)]\n",
    "\n",
    "        # Asignar resultados al DataFrame original 'b' usando el √≠ndice original\n",
    "        b.loc[g['index'], 'distance_km'] = dists\n",
    "        b.loc[g['index'], 'velocity_kmh'] = vels\n",
    "        b.loc[g['index'], 'acceleration_kmh2'] = accs\n",
    "\n",
    "    # Calcular daylight y variables ambientales\n",
    "    b[['daylight_hours', 'is_polar_night', 'is_midnight_sun']] = b.progress_apply(\n",
    "        lambda r: pd.Series(get_daylight(r['lat2'], r['lon2'], r['date_str'])), axis=1)\n",
    "\n",
    "    for var in vars_env:\n",
    "        b[var] = b.progress_apply(lambda r: get_env(var, r['proj_x'], r['proj_y'], r['date_str']), axis=1)\n",
    "\n",
    "    res.append(b)\n",
    "\n",
    "    df_final = pd.concat(res).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5250e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearing_mc(lat1, lon1, lat2, lon2, se_x1, se_y1, se_x2, se_y2, n=30):\n",
    "    '''\n",
    "        Funci√≥n para direcci√≥n con propagaci√≥n de error (Monte Carlo)\n",
    "    '''\n",
    "    bearings = []\n",
    "    for _ in range(n):\n",
    "        l1 = np.random.normal(lat1, se_y1)\n",
    "        o1 = np.random.normal(lon1, se_x1)\n",
    "        l2 = np.random.normal(lat2, se_y2)\n",
    "        o2 = np.random.normal(lon2, se_x2)\n",
    "\n",
    "        œÜ1, œÜ2 = radians(l1), radians(l2)\n",
    "        Œª1, Œª2 = radians(o1), radians(o2)\n",
    "        y = sin(Œª2 - Œª1) * cos(œÜ2)\n",
    "        x = cos(œÜ1) * sin(œÜ2) - sin(œÜ1) * cos(œÜ2) * cos(Œª2 - Œª1)\n",
    "        Œ∏ = degrees(arctan2(y, x))\n",
    "        bearings.append((Œ∏ + 360) % 360)\n",
    "    return np.mean(bearings)\n",
    "\n",
    "# Calcular previos para cambio de direcci√≥n\n",
    "df_final['prev_lat'] = df_final.groupby('UniqueAnimalID')['adj_lat'].shift(1)\n",
    "df_final['prev_lon'] = df_final.groupby('UniqueAnimalID')['adj_lon'].shift(1)\n",
    "df_final['prev_se_x'] = df_final.groupby('UniqueAnimalID')['se_mu_x'].shift(1)\n",
    "df_final['prev_se_y'] = df_final.groupby('UniqueAnimalID')['se_mu_y'].shift(1)\n",
    "\n",
    "# Calcular bearing con error\n",
    "df_final['bearing'] = df_final.progress_apply(\n",
    "    lambda r: bearing_mc(\n",
    "        r['prev_lat'], r['prev_lon'], r['adj_lat'], r['adj_lon'],\n",
    "        r['prev_se_x'], r['prev_se_y'], r['se_mu_x'], r['se_mu_y']\n",
    "    ) if pd.notnull(r['prev_lat']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Calcular cambio de direcci√≥n\n",
    "df_final['prev_bearing'] = df_final.groupby('UniqueAnimalID')['bearing'].shift(1)\n",
    "df_final['bearing_change'] = df_final.apply(\n",
    "    lambda r: abs((r['bearing'] - r['prev_bearing'] + 180) % 360 - 180)\n",
    "    if pd.notnull(r['prev_bearing']) else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46aa9d2b",
   "metadata": {},
   "source": [
    "#### *__Estaciones en Beaufort y en Chukchi__*\n",
    "\n",
    "¬øLas estaciones en Beaufort y Chukchi son como en Europa?\n",
    "\n",
    "*No exactamente.* Aunque puedes usar las estaciones astron√≥micas est√°ndar (primavera: marzo-mayo, verano: junio-agosto, etc.), las regiones √°rticas como Beaufort y Chukchi tienen din√°micas clim√°ticas muy distintas. All√≠, el a√±o suele dividirse en:\n",
    "\n",
    "    Invierno largo (noviembre a abril): temperaturas extremadamente bajas, hielo marino extenso.\n",
    "\n",
    "    Verano corto (junio a septiembre): deshielo, mayor actividad biol√≥gica.\n",
    "\n",
    "    Transiciones (mayo y octubre): condiciones variables, importantes para migraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e733b051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueAnimalID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>mu_lat</th>\n",
       "      <th>mu_lon</th>\n",
       "      <th>se_mu_x</th>\n",
       "      <th>se_mu_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134907</th>\n",
       "      <td>215</td>\n",
       "      <td>2009-08-19 06:00:00</td>\n",
       "      <td>70.8765</td>\n",
       "      <td>-152.5880</td>\n",
       "      <td>995</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134908</th>\n",
       "      <td>215</td>\n",
       "      <td>2009-08-19 12:00:00</td>\n",
       "      <td>70.8765</td>\n",
       "      <td>-152.5840</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134909</th>\n",
       "      <td>215</td>\n",
       "      <td>2009-08-19 18:00:00</td>\n",
       "      <td>70.8765</td>\n",
       "      <td>-152.5775</td>\n",
       "      <td>493</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134910</th>\n",
       "      <td>215</td>\n",
       "      <td>2009-08-20 00:00:00</td>\n",
       "      <td>70.8750</td>\n",
       "      <td>-152.5720</td>\n",
       "      <td>273</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134911</th>\n",
       "      <td>215</td>\n",
       "      <td>2009-08-20 06:00:00</td>\n",
       "      <td>70.8693</td>\n",
       "      <td>-152.5407</td>\n",
       "      <td>974</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UniqueAnimalID           timestamp   mu_lat    mu_lon  se_mu_x  \\\n",
       "134907             215 2009-08-19 06:00:00  70.8765 -152.5880      995   \n",
       "134908             215 2009-08-19 12:00:00  70.8765 -152.5840     1080   \n",
       "134909             215 2009-08-19 18:00:00  70.8765 -152.5775      493   \n",
       "134910             215 2009-08-20 00:00:00  70.8750 -152.5720      273   \n",
       "134911             215 2009-08-20 06:00:00  70.8693 -152.5407      974   \n",
       "\n",
       "        se_mu_y  \n",
       "134907      995  \n",
       "134908     1080  \n",
       "134909      493  \n",
       "134910      273  \n",
       "134911      974  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df = df[(df['timestamp'].dt.year == 2009)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb601439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc08d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignar_season(date):\n",
    "    month = date.month\n",
    "    if month in [6, 7, 8, 9]:\n",
    "        return \"verano\"\n",
    "    elif month in [11, 12, 1, 2, 3, 4]:\n",
    "        return \"invierno\"\n",
    "    else:\n",
    "        return \"transicion\"\n",
    "\n",
    "df['month'] = df['date'].dt.month\n",
    "df['season'] = df['date'].apply(asignar_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ad60c",
   "metadata": {},
   "source": [
    "#### *__Distance_per_day__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a874bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final['date'] = df_final['timestamp'].dt.date\n",
    "daily_distance = df_final.groupby(['UniqueAnimalID', 'date'])['distance_km'].sum().reset_index()\n",
    "daily_distance.rename(columns={'distance_km': 'distance_per_day'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236228ce",
   "metadata": {},
   "source": [
    "#### __Merge final__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d7cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge con df_final\n",
    "df_final = df_final.merge(daily_distance, on=['UniqueAnimalID', 'date'], how='left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a64f82",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "# SAVE RICH DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58534cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('polar_bear_processed_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
