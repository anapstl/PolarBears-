{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Instalar dependencias\n",
        "!pip install xarray netCDF4 geopy tqdm skyfield requests"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Importar librerías\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr\n",
        "from geopy.distance import geodesic\n",
        "from tqdm.notebook import tqdm\n",
        "from functools import lru_cache\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from skyfield.api import load, Topos\n",
        "from skyfield.almanac import sunrise_sunset, find_discrete\n",
        "import requests\n",
        "\n",
        "tqdm.pandas()"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Funciones de cálculo para posición, distancia y tiempo solar\n",
        "def adjusted_position_mc(lat, lon, se_x, se_y, n_samples=50):\n",
        "    lats = np.random.normal(lat, se_y, n_samples)\n",
        "    lons = np.random.normal(lon, se_x, n_samples)\n",
        "    return lats.mean(), lons.mean()\n",
        "\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "    R = 6371.0\n",
        "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
        "    dlat = lat2 - lat1; dlon = lon2 - lon1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1)*np.cos(lat2)*np.sin(dlon/2)**2\n",
        "    return 2*R*np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "\n",
        "def calculate_velocity(distance_km, time_sec):\n",
        "    return (distance_km / time_sec) * 3600 if time_sec>0 else 0\n",
        "\n",
        "def calculate_acceleration(v1, v2, time_sec):\n",
        "    return (v2 - v1) / (time_sec/3600) if time_sec>0 else 0\n",
        "\n",
        "# 4. Efemérides – horas de luz\n",
        "eph = load('de421.bsp')\n",
        "ts = load.timescale()\n",
        "@lru_cache(maxsize=50000)\n",
        "def get_daylight(lat, lon, date_str):\n",
        "    d = datetime.strptime(date_str,'%Y-%m-%d').replace(tzinfo=timezone.utc)\n",
        "    t0 = ts.utc(d.year, d.month, d.day)\n",
        "    t1 = ts.utc((d+timedelta(days=1)).year, (d+timedelta(days=1)).month, (d+timedelta(days=1)).day)\n",
        "    obs = Topos(latitude_degrees=lat, longitude_degrees=lon)\n",
        "    f = sunrise_sunset(eph, obs)\n",
        "    times, events = find_discrete(t0, t1, f)\n",
        "    sunr = suns = None\n",
        "    for ti, ev in zip(times, events):\n",
        "        if ev==1: sunr = ti.utc_datetime()\n",
        "        elif ev==0: suns = ti.utc_datetime()\n",
        "    if sunr and suns:\n",
        "        dh = (suns - sunr).total_seconds()/3600\n",
        "        return dh, False, False\n",
        "    else:\n",
        "        alt = eph['Earth']+obs\n",
        "        sun_alt = alt.at(t0).observe(eph['Sun']).apparent().altaz()[0].degrees\n",
        "        if sun_alt>0: return 24.0, False, True\n",
        "        else: return 0.0, True, False\n",
        "\n",
        "# 5. Datos ambientales remotos\n",
        "url = 'https://polarwatch.noaa.gov/erddap/griddap/nsidcG02202v4nh1day'\n",
        "ds = xr.open_dataset(url, engine='netcdf4').sel(time=slice('1985-01-01','2017-12-31'))\n",
        "vars_env = ['seaice_conc','temp_surface','wind_speed','cloud_cover']\n",
        "@lru_cache(maxsize=50000)\n",
        "def get_env(ds, var, lat, lon, date_str):\n",
        "    try:\n",
        "        return float(ds[var].sel(time=np.datetime64(date_str), latitude=lat, longitude=lon, method='nearest').values)\n",
        "    except: return np.nan"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Cargar y ordenar CSV principal\n",
        "df = pd.read_csv('polarBear_CTCRWlocations_chukchiBeaufort_1985-2017.csv')\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df = df.sort_values(['UniqueAnimalID','timestamp']).reset_index(drop=True)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Procesamiento por batches\n",
        "batch_size = 10000\n",
        "res = []\n",
        "for i in tqdm(range(0, len(df), batch_size), desc='Batches'):\n",
        "    b = df.iloc[i:i+batch_size].copy()\n",
        "    b['adj_lat'], b['adj_lon'] = zip(*b.progress_apply(lambda r: adjusted_position_mc(r['mu_lat'],r['mu_lon'],r['se_mu_x'],r['se_mu_y']),axis=1))\n",
        "    b['date_str'] = b['timestamp'].dt.strftime('%Y-%m-%d')\n",
        "    b['lat2'] = b['adj_lat'].round(2)\n",
        "    b['lon2'] = b['adj_lon'].round(2)\n",
        "    dists, vels, accs = [], [], []\n",
        "    for aid, g in b.groupby('UniqueAnimalID'):\n",
        "        g = g.reset_index(drop=True)\n",
        "        ds_ = [0]; vs=[0]; ac=[0]\n",
        "        for j in range(1,len(g)):\n",
        "            dt = (g.loc[j,'timestamp']-g.loc[j-1,'timestamp']).total_seconds()\n",
        "            dk = haversine_distance(g.loc[j-1,'adj_lat'],g.loc[j-1,'adj_lon'],g.loc[j,'adj_lat'],g.loc[j,'adj_lon'])\n",
        "            dists.append(dk); vels.append(calculate_velocity(dk,dt))\n",
        "        for j in range(1,len(vels)):\n",
        "            dt=(g.loc[j,'timestamp']-g.loc[j-1,'timestamp']).total_seconds()\n",
        "            accs.append(calculate_acceleration(vels[j-1],vels[j],dt))\n",
        "    b['distance_km']=dists; b['velocity_kmh']=vels; b['acceleration_kmh2']=accs\n",
        "    b[['daylight_hours','is_polar_night','is_midnight_sun']] = b.progress_apply(lambda r: pd.Series(get_daylight(r['lat2'],r['lon2'],r['date_str'])), axis=1)\n",
        "    for var in vars_env:\n",
        "        b[var] = b.progress_apply(lambda r: get_env(ds,var,r['lat2'],r['lon2'],r['date_str']),axis=1)\n",
        "    res.append(b)\n",
        "df_final = pd.concat(res).reset_index(drop=True)\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Revisa resultados\n",
        "df_final.head()"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
    "language_info": { "name": "python", "version": "3.10" }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
